{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fa61bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "dataset_folder = '../HSPP Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7d4c6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_notable_groups(df):\n",
    "    #Keyword/phrase lists\n",
    "    client_death = [\"Death\", \"Deceased\"]\n",
    "    client_hospitalization = [\"Hospitalization\", \"Admitted to Hospital\", \"In Hospital\", \"Health/Hospital\", \n",
    "        \"hospital\", \"hospital\", \"hospitalization\", \"admitted to hospital\", \"In hospital\"]\n",
    "    client_fall = [\"Injury/Fall\", \"Injury\", \"Near Fall (stabilized or assisted down)\", \"Close call - fall\",\n",
    "        \"Fell to Floor (witnessed)\", \"Found on Floor (unwitnessed)\", \"Client/Family Reported Fall\", \n",
    "        \"client fall and change of hours needed\", \"caregiver reported client had a fall\", \"fall\", \"Fall\", \"Client had a fall and went by ambulance to hospital\",\n",
    "        \"Fell onto couch did not reach floor\", \"fall/incident\"]\n",
    "    client_health_decline = [\"Health Decline\", \"Cognitive/Mental Health Decline\", \"Physical Health Decline\", \n",
    "        \"Cognitive Health Decline\", \"Visit to ER\", \"Phyical Health Decline\", \"Memory decline\", \n",
    "        \"Trip to hospital/client unresponsive\", \"Health Status Decline\", \"Visit to ER\", \"Physical Health Concerns\", \n",
    "        \"taken by ambulance to hospita;l\", \"Multiple Suicide Attempts\", \"client went by ambulance to the hospital\", \"Client taken to hospital\", \n",
    "        \"Mobility decline\", \"Decreased balance over time, refusal to use assistive devices properly\", \"Health decline concern\"]\n",
    "    client_account_status = [\"Account Activated/Reactivated\", \"Service Terminated\", \"Service Suspended\", \"suspended services\", \n",
    "        \"Suspend services\", \"Resuming services\", \"Termination Of Services\", \"Termination of Service\", \"Suspending services\", \"Admitted to Hospice Care\",\n",
    "        \"Service Cancellation\", \"suspended services COVID-19\", \"Cancelation\", \"Cancellation of services\", \"cancelling services....\", \"Cancellation of services\"]\n",
    "    client_potential_LOC_change_health = [\"Behaviour\", \"behavior\", \"Client Behavior\", \"client behaviour\", \"Behavior\", \n",
    "        \"behavioural concern\",\"Client behavior\", \"Client Behavior Concern\", \"Behavior Issue\", \"Client behavior concerns\", \"New Diagnosis\", \"Reassessment\", \n",
    "        \"Health/Cognitive Update\", \"Returned from Hospital\", \"reassessment\", \"re-assessment\", \"Seizure\", \"seizure\", \n",
    "        \"ambulance called\", \"client discharged\", \"first aid needed\", \"Re-assessment\", \"Mental Health Concern\", \"HEALTH CONCERN\",\n",
    "        \"health concern\", \"Health Concern\", \"Change in health\", \"Significant change\", \"Significant Change\",\n",
    "        \"Near Choking Incident\", \"Choking\", \"Health Concern call to POA\", \"Health Concerns\", \"Feeling unwell/ High blood sugar\", \n",
    "        \"Health Change\", \"High Blood Pressure\", \"Urinary tract infection\", \"Urinary Tract Infections\", \"Client has high blood pressure and had swollen ankle\",\n",
    "        \"Client is not happy\", \"Chest Pain\", \"Client in Pain\", \"car accident\", \"suicidal actions\", \"health and memory concerns\", \"Feeling Unwell\", \n",
    "        \"Health Concern/ Support Concern\", \"Low Blood Sugar - Ambulance called\", \"Health Status Dramatic Change\", \"Concern about wandering\", \"Confused Client\",\n",
    "        \"Unsafe Steps\"]\n",
    "    client_plan_update = [\"Environment/Scheduling Preferences Update\", \"Care Plan Update\", \"Scheduling Issue\"]\n",
    "    client_health_status = [\"Health Status\", \"Update\", \"Assessment\", \"health status\", \"Physically Health Update\", \"Physical Health Update\", \n",
    "        \"Health Status Update\", \"Health Update\", \"Physical Update\", \"Overall Health Status\", \"Mental Health Status\"]\n",
    "    client_covid = [\"COVID-19 CASE\"]\n",
    "\n",
    "    notable_type = []\n",
    "    # Look at notables in order of importance for the type of label to our analyses \n",
    "    # so that we put each notable in the most appropriate (i.e. interesting) group:\n",
    "    # deaths > \n",
    "    #   hospitalizations > \n",
    "    #       injuries/falls > \n",
    "    #           health decline > \n",
    "    #               account status change > \n",
    "    #                   covid > \n",
    "    #                       Level of care (LOC) change > \n",
    "    #                           Potential LOC change (health) > \n",
    "    #                               potential LOC change (non-health) > \n",
    "    #                                   Client Issues/Incidents/Complaint > \n",
    "    #                                       Care plan/Scheduling update Health Status Check > \n",
    "    #                                           Other\n",
    "    for i in df.index:\n",
    "        # Step 1: deaths\n",
    "        if (df['notable_type'][i] in client_death) or \\\n",
    "            (df['record_type'][i] in client_death) or \\\n",
    "            (df['nature_of_incident'][i] in client_death) or \\\n",
    "            (df['reason'][i] in client_death):\n",
    "            notable_type.append([df['notableId'][i], \"Death\"])\n",
    "\n",
    "        # Step 2: hospitalizations\n",
    "        elif (df['notable_type'][i] in client_hospitalization) or \\\n",
    "            (df['record_type'][i] in client_hospitalization) or \\\n",
    "            (df['nature_of_incident'][i] in client_hospitalization) or \\\n",
    "            (df['reason'][i] in client_hospitalization):\n",
    "            notable_type.append([df['notableId'][i], \"Hospitalization\"])\n",
    "\n",
    "        # Step 3: injuries and falls\n",
    "        elif (df['notable_type'][i] in client_fall) or \\\n",
    "            (df['record_type'][i] in client_fall) or \\\n",
    "            (df['nature_of_incident'][i] in client_fall) or \\\n",
    "            (df['reason'][i] in client_fall):\n",
    "            notable_type.append([df['notableId'][i], \"Injury/Fall\"]) \n",
    "\n",
    "        # Step 4: Health decline\n",
    "        elif (df['notable_type'][i] in client_health_decline) or \\\n",
    "            (df['record_type'][i] in client_health_decline) or \\\n",
    "            (df['nature_of_incident'][i] in client_health_decline) or \\\n",
    "            (df['reason'][i] in client_health_decline):\n",
    "            notable_type.append([df['notableId'][i], \"Health Decline\"])\n",
    "\n",
    "        # Step 5: Account status change\n",
    "        elif (df['notable_type'][i] in client_account_status ) or \\\n",
    "            (df['record_type'][i] in client_account_status ) or \\\n",
    "            (df['nature_of_incident'][i] in client_account_status ) or \\\n",
    "            (df['reason'][i] in client_account_status ):\n",
    "            notable_type.append([df['notableId'][i], \"Account Status Change\"]) \n",
    "\n",
    "        # Step 5: got CoVID\n",
    "        elif (df['notable_type'][i] in client_covid):\n",
    "            notable_type.append([df['notableId'][i], \"CoVID 19\"])\n",
    "\n",
    "        # Step 6: Level of care (LOC) change (but no details on level up or down provided)\n",
    "        elif (df['record_type'][i] == \"Level_of_Care_Change\"):\n",
    "            notable_type.append([df['notableId'][i], \"LOC Change\"]) \n",
    "\n",
    "        # Step 7: Potential for LOC change due to health changes\n",
    "        elif (df['notable_type'][i] in client_potential_LOC_change_health ) or \\\n",
    "            (df['record_type'][i] in client_potential_LOC_change_health ) or \\\n",
    "            (df['nature_of_incident'][i] in client_potential_LOC_change_health ) or \\\n",
    "            (df['reason'][i] in client_potential_LOC_change_health ):\n",
    "            notable_type.append([df['notableId'][i], \"Potential LOC Change (Health)\"]) \n",
    "\n",
    "        # Step 8: Potential for LOC change due to non-health changes\n",
    "        elif (df['notable_type'][i] == \"Change in Living Arrangements\") or \\\n",
    "            (df['notable_type'][i] == \"Family Support/Problems\"):\n",
    "            notable_type.append([df['notableId'][i], \"Potential LOC Change (Non-Health)\"])   \n",
    "\n",
    "        # Step 9: Client Issues/Incidents/Complaint\n",
    "        elif (df['notable_type'][i] == \"Client Incident\") or \\\n",
    "            (df['notable_type'][i] == \"Client Complaint\") or \\\n",
    "            (df['notable_type'][i] == \"Client Issue\"):\n",
    "            notable_type.append([df['notableId'][i], \"Client Issue/Incident/Complaint\"]) \n",
    "\n",
    "        #Step 10: Care plan/Scheduling update \n",
    "        elif (df['notable_type'][i] in client_plan_update):\n",
    "            notable_type.append([df['notableId'][i], \"Care Plan/Schedule Update\"]) \n",
    "\n",
    "        # Step 11: Health Status Check\n",
    "        elif (df['notable_type'][i] in client_health_status ) or \\\n",
    "            (df['record_type'][i] in client_health_status ) or \\\n",
    "            (df['nature_of_incident'][i] in client_health_status ) or \\\n",
    "            (df['reason'][i] in client_health_status ):\n",
    "            notable_type.append([df['notableId'][i], \"Health Status Check\"])\n",
    "        #Step 12: Anything left over put in the 'Other' category\n",
    "        else:\n",
    "            notable_type.append([df['notableId'][i], \"Other\"])\n",
    "    \n",
    "    df_out = df.merge(pd.DataFrame(notable_type, columns = ['notableId', 'grp_nt_type']), left_on='notableId', right_on='notableId', how='left')\n",
    "    df_out.date = pd.to_datetime(df_out.date, utc=True)\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f75a84b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 419 entries, 0010A000003UCPIQA4 to 001U000001k5HVMIA2\n",
      "Data columns (total 13 columns):\n",
      " #   Column                             Non-Null Count  Dtype\n",
      "---  ------                             --------------  -----\n",
      " 0   Account Status Change              419 non-null    bool \n",
      " 1   Care Plan/Schedule Update          419 non-null    bool \n",
      " 2   Client Issue/Incident/Complaint    419 non-null    bool \n",
      " 3   CoVID 19                           419 non-null    bool \n",
      " 4   Death                              419 non-null    bool \n",
      " 5   Health Decline                     419 non-null    bool \n",
      " 6   Health Status Check                419 non-null    bool \n",
      " 7   Hospitalization                    419 non-null    bool \n",
      " 8   Injury/Fall                        419 non-null    bool \n",
      " 9   LOC Change                         419 non-null    bool \n",
      " 10  Other                              419 non-null    bool \n",
      " 11  Potential LOC Change (Health)      419 non-null    bool \n",
      " 12  Potential LOC Change (Non-Health)  419 non-null    bool \n",
      "dtypes: bool(13)\n",
      "memory usage: 8.6+ KB\n"
     ]
    }
   ],
   "source": [
    "rawfile_location_notables = os.path.join(dataset_folder, 'notables_prod.csv')\n",
    "rawfile_location_control_notables = os.path.join(dataset_folder, 'control_notables_prod.csv')\n",
    "    \n",
    "wci_column_drop = [\n",
    "    'last_modified_date_time', 'area', 'action_taken', 'time_of', 'status', 'created_timestamp', \n",
    "    'updated_timestamp', 'updated_author', 'created_author']\n",
    "\n",
    "control_column_drop = ['last_modified_date_time', 'area', 'time_of', 'status', 'place_of_incident',\n",
    "                       'date_of_notification', 'action_taken', 'other_type',\n",
    "                       'prior_level_of_care', 'new_level_of_care']\n",
    "\n",
    "df_notable_in = pd.read_csv(rawfile_location_notables)\n",
    "df_notable_in.drop(columns=wci_column_drop, inplace=True)\n",
    "df_notable_in.rename(columns= {'client_id':'clientId', 'date_of':'date', 'notable_id':'notableId'}, inplace=True)\n",
    "\n",
    "df_control_notable_in = pd.read_csv(rawfile_location_control_notables)\n",
    "df_control_notable_in.drop(columns=control_column_drop, inplace=True)\n",
    "df_control_notable_in.rename(columns= {'client_id':'clientId', 'date_of':'date', 'notable_id':'notableId'}, inplace=True)\n",
    "\n",
    "df_notables = create_notable_groups(df_notable_in).reset_index(drop=True)\n",
    "    \n",
    "df_control_notables = create_notable_groups(df_control_notable_in).reset_index(drop=True)\n",
    "    \n",
    "df_notables['wci_control_client'] = False;\n",
    "df_control_notables['wci_control_client'] = True;\n",
    "\n",
    "df_notables = pd.concat([df_notables, df_control_notables])\n",
    "\n",
    "df_notables = df_notables \\\n",
    "    .groupby(['clientId', 'grp_nt_type']).any().max(axis=1) \\\n",
    "    .reset_index('grp_nt_type') \\\n",
    "    .pivot(columns='grp_nt_type', values=0) \\\n",
    "    .fillna(False)\n",
    "\n",
    "df_notables.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e191e019",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ast\n",
    "\n",
    "# HSPP Health Indicators\n",
    "#\n",
    "# In addition to the pitch-toolkit survey data, a set of basic health-related measures are recorded in each client visit. \n",
    "# These measures are part of Kindreds regular care, and pulled from the Kindred datasets using our \n",
    "# vsf-analytics::Migrate.java utility (i.e., a cron-style data migration).\n",
    "#\n",
    "# Health Indicators are stored as a column in the vsf-analytics::hspp_assessment table, *roughly* encoded as a JSON string \n",
    "# (see `_parse_encoded_health_indicators_string` utility for a caveat). These measures are captured during *every* visit, \n",
    "# and may therefore change over time (e.g., a patient may acquire a new assistive device such as a cane or walker).\n",
    "#\n",
    "# This module exposes a single `get_health_indicators` utility function that parses, processes, and sanitizes these health \n",
    "# indicators for all clients in the dataset. Specifically, this function returns a `two-tuple` of pandas data frames, \n",
    "# formatted as follows:\n",
    "#\n",
    "#   (per_client_health_indicators, per_visit_health_indicators)\n",
    "#    \n",
    "# ...where:\n",
    "#\n",
    "#   - `per_client_health_indicators` - A data frame with a single row for each *client* in the dataset. This data frame \n",
    "#     will include clients from both the `control` and `wci` groups. For clients with more than one set of recorded health \n",
    "#     indicators in the dataset, this data frame will contain the *most recently reported* values.\n",
    "# \n",
    "#   - `per_visit_health_indicators` - A data frame with a row for each *visit* in the dataset. Note however, that only \n",
    "#     `wci` group clients will have more than a single occurence in the data frame.\n",
    "#\n",
    "# TODO: This utility function reports a `DataFrame is highly fragmented` Performance Warning because of the way I've\n",
    "# incrementally built up the sanitized/processed columns in the original dataframe. I believe that the warning is telling\n",
    "# us that there is no guarantee that the entire df will occupy a single contiguous chunck of memory, which could hurt the\n",
    "# performance of some native numpy routines (i.e., that expect to operate on contiguous arrays).\n",
    "#\n",
    "# The fix for this is probably to rework the private utilities in this module to each return separate dataframes, and then\n",
    "# concatenate all of these together for the final return. However, until performance is actually a concern, I think we are\n",
    "# fine.\n",
    "\n",
    "def get_health_indicators(dataset_folder_name):\n",
    "    per_visit_indicators = _import_health_indicators(dataset_folder_name)\n",
    "    \n",
    "    _create_onehot_mental_columns(per_visit_indicators)\n",
    "    _create_onehot_physical_columns(per_visit_indicators)\n",
    "    _create_onehot_assistive_devices_columns(per_visit_indicators)\n",
    "    _create_boolean_smoker_column(per_visit_indicators)\n",
    "    _create_boolean_pets_column(per_visit_indicators)\n",
    "    _create_simplified_house_condition_column(per_visit_indicators)\n",
    "    _convert_to_friendly_dates(per_visit_indicators)\n",
    "    \n",
    "    per_client_indicators = per_visit_indicators.groupby('client_id').first()\n",
    "    \n",
    "    return per_client_indicators\n",
    "\n",
    "\n",
    "\n",
    "# Importing the Health Indicators Dataset\n",
    "#\n",
    "# Health indicators are stored as a string-encoded object in the `health_indicators` field of each visit record. \n",
    "# We can transform this into a valid python object using the `parse_health_indicators` utility define above.\n",
    "# For now, I'm throwing away the outer `visit` fields, as these are also available within the list of health indicators.\n",
    "def _import_health_indicators(dataset_folder_name):\n",
    "    control_group_filename = 'control_assessment_Data.csv'\n",
    "    wci_group_filename = 'assessment_Data.csv'\n",
    "    \n",
    "    control_group_health_indicators = _read_health_indicators_from_file(dataset_folder_name + '/' + control_group_filename)\n",
    "    wci_group_health_indicators = _read_health_indicators_from_file(dataset_folder_name + '/' + wci_group_filename)\n",
    "    \n",
    "    # The `wci_control_client` health indicator field denotes whether this client was in the intervention or control group of the experiment. \n",
    "    # However, this field isn't populated for every record in this dataset (e.g., earlier visits before this column was added)\n",
    "    # Therefore, explicitly assign a value for every record.\n",
    "    control_group_health_indicators['wci_control_client'] = True\n",
    "    wci_group_health_indicators['wci_control_client'] = False\n",
    "\n",
    "    return pd.concat([control_group_health_indicators, wci_group_health_indicators], axis=0)\n",
    "\n",
    "\n",
    "def _read_health_indicators_from_file(filename):\n",
    "    visits = pd.read_csv(filename)\n",
    "    \n",
    "    # Each set of \"health indicators\" is encoded in the `health_indicators` column of the df.\n",
    "    # First, we need to parse each string-encoded entry...\n",
    "    visits.health_indicators = visits.health_indicators.map(_parse_encoded_health_indicators_string)\n",
    "\n",
    "    # ...The health indicators are now represeted as a valid python object. However, this object is\n",
    "    # still stored in a single column of the data frame.\n",
    "    #\n",
    "    # Thefore, \"explode\" this object and create a new data frame that represents each \"health indicator\" field as a separate column\n",
    "    return pd.DataFrame(list(visits.health_indicators))\n",
    "\n",
    "\n",
    "# Kindred records a set of \"health indicators\" for each of their client (e.g., demographics, health conditions, details of their care plan). \n",
    "# These \"health indicators\" are stored as a string-encoded field, however, the exact encoding method seems to differ between clients \n",
    "# (e.g., some seem to be encoded in JSON, while others use python literal dictionary format (e.g., the result of calling dict.repr()).\n",
    "#\n",
    "# This utility encapsulates these encoding format details by trying all possible expected encodings until one works. A \n",
    "# `HealthIndicatorsDecodeError` is raised when an unexpected formatting is encountered.\n",
    "def _parse_encoded_health_indicators_string(health_indicators_string):\n",
    "    try:\n",
    "        return json.loads(health_indicators_string)\n",
    "    except json.JSONDecodeError:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        return ast.literal_eval(health_indicators_string)\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    raise HealthIndicatorsDecodeError()\n",
    "    \n",
    "class HealthIndicatorsDecodeError(Exception):\n",
    "    pass\n",
    "\n",
    "    \n",
    "# Metal Health Details - Transform to Onehot Fields\n",
    "#\n",
    "# We can convert the `mental_health_details` field to a series of onehot fields, each indicating\n",
    "# the presence of the corresponding condition.\n",
    "#\n",
    "# TODO: Note that I've currently manually created this list of `mental_conditions` by visually inspecting\n",
    "# the `value_counts()` output from the `mental_health_details` column - in the future we could programatically, \n",
    "# however I think this is fine.\n",
    "def _create_onehot_mental_columns(health_indicators_df):\n",
    "    mental_conditions = [\n",
    "        'dementia', \n",
    "        \"alzhemier's\",\n",
    "        'depression',\n",
    "        'short-term memory impairment',\n",
    "        'loss of orientation',\n",
    "        'anxiety',\n",
    "        'bi-polar', \n",
    "        'other'\n",
    "    ]\n",
    "    \n",
    "    for condition in mental_conditions:\n",
    "        def has_condition(condition_string):\n",
    "            return condition in condition_string.lower()\n",
    "\n",
    "        column_label = 'has_mental_' + condition.replace(' ', '_')\n",
    "        health_indicators_df[column_label] = health_indicators_df.mental_health_details.map(lambda x: int(has_condition(x)), na_action='ignore')\n",
    "\n",
    "    health_indicators_df['mental_count'] = health_indicators_df.filter(regex='^has_mental_').sum(axis=1)\n",
    "\n",
    "\n",
    "# Physical Health Details - Transform to Onehot Fields\n",
    "#\n",
    "# Similar to the `mental_health_details` field, however, this appears to be a free-form text\n",
    "# data field as opposed to choice dropdown. Looks like employees were instructed to use a\n",
    "# semi-colon separate list later in the program, however still pretty variable formatting.\n",
    "def _create_onehot_physical_columns(health_indicators_df):\n",
    "    physical_conditions = [\n",
    "        'diabetes', \n",
    "        'stroke', \n",
    "        'high blood pressure', \n",
    "        'cancer', \n",
    "        'copd', \n",
    "        'arthritis', \n",
    "        'high cholesterol', \n",
    "        'mobility issues', \n",
    "        'vision impairment', \n",
    "        'hearing impairment',\n",
    "        'chronic pain',\n",
    "        'gastro-intestinal issue',\n",
    "        'heart failure',\n",
    "        'other'\n",
    "    ]\n",
    "\n",
    "    for condition in physical_conditions:\n",
    "        def has_condition(conditions_string):\n",
    "            return condition in conditions_string.lower()\n",
    "\n",
    "        column_label = 'has_physical_' + condition.replace(' ', '_')\n",
    "        health_indicators_df[column_label] = health_indicators_df.health_physical_issues_details.map(lambda x: int(has_condition(x)), na_action='ignore')\n",
    "\n",
    "\n",
    "    health_indicators_df['physical_count'] = health_indicators_df.filter(regex='^has_physical_').sum(axis=1)\n",
    "\n",
    "# Special Equipment Details - Transform to Onehot fields\n",
    "#\n",
    "# Again, this `special_equipment_details` columns seems to be a free-text field. Transform\n",
    "# into a series of onehot fields using a keyword-matching approach. The list of keywords was\n",
    "# determined by visually inspecting the `value_counts()` output.\n",
    "def _create_onehot_assistive_devices_columns(health_indicators_df):\n",
    "    mobility_assistance_devices = [\n",
    "        'cane',\n",
    "        'walker',\n",
    "        'wheelchair',\n",
    "        'tub',\n",
    "        'toilet',\n",
    "        'commode',\n",
    "        'catheter',\n",
    "        'grab bar',\n",
    "        'scooter',\n",
    "        'rollator',\n",
    "        'crutches',\n",
    "        'bed railing',\n",
    "        'shower chair',\n",
    "        'hospital bed',\n",
    "        'lifeline',\n",
    "    ]\n",
    "\n",
    "    for device in mobility_assistance_devices:\n",
    "        def has_device(device_string):\n",
    "            return device in device_string.lower()\n",
    "\n",
    "        column_label = 'has_mobility_' + device.replace(' ', '_')\n",
    "        health_indicators_df[column_label] = health_indicators_df.special_equipment_details.map(lambda x: int(has_device(x)), na_action='ignore')\n",
    "\n",
    "    health_indicators_df['mobility_count'] = health_indicators_df.filter(regex='^has_mobility_').sum(axis=1)\n",
    "\n",
    "\n",
    "# Smoker\n",
    "#\n",
    "# This column is currently categorical -- let's collapse into a boolean column...\n",
    "#   - True <= 'Client smokes outside'\n",
    "#   - True <= 'Client smokes inside'\n",
    "#   - False <= 'Client is a non-smoker'\n",
    "def _create_boolean_smoker_column(health_indicators_df):\n",
    "    health_indicators_df['is_smoker'] = health_indicators_df.client_smoker.map(lambda s: int('smokes' in s), na_action='ignore')\n",
    "\n",
    "\n",
    "# Pets\n",
    "#\n",
    "# Lets collapse this into a boolean column indicating presence of *any* pet\n",
    "def _create_boolean_pets_column(health_indicators_df):\n",
    "    pet_keywords = ['dog', 'cat', 'other']\n",
    "\n",
    "    def has_pets(pet_string):\n",
    "        return any([keyword in pet_string.lower() for keyword in pet_keywords])\n",
    "\n",
    "    health_indicators_df['has_pets'] = health_indicators_df.pets_details.map(lambda x: int(has_pets(x)), na_action='ignore')\n",
    "\n",
    "\n",
    "# House Condition\n",
    "#\n",
    "# This category appears to be a free-text field...\n",
    "# This is a pretty good apprach, but note that it does mis-categories some entries (e.g., \"house is not tidy\")\n",
    "def _create_simplified_house_condition_column(health_indicators_df):\n",
    "    label_keywords = {\n",
    "        'clean': ['tidy', 'acceptable', 'clean', 'good', 'well kept' 'excellent', 'spotless', 'immaculate', 'impeccable', 'organized'],\n",
    "        'dirty': ['cluttered', 'crowded', 'rough', 'poor', 'disrepair', 'messy']\n",
    "    }\n",
    "\n",
    "    def parse_house_condition(condition_string):\n",
    "        lowered = condition_string.lower()\n",
    "        for (label, keywords) in label_keywords.items():\n",
    "            for keyword in keywords:\n",
    "                if keyword in lowered:\n",
    "                    return label\n",
    "        return 'n/a'\n",
    "\n",
    "    health_indicators_df['house_condition'] = health_indicators_df.condition_of_client_s_house.map(parse_house_condition, na_action='ignore')\n",
    "\n",
    "\n",
    "# Convert string-dates to date objects for easier plotting\n",
    "def _convert_to_friendly_dates(health_indicators_df):\n",
    "    for column in ['assessment_date', 'service_start_date']:\n",
    "        health_indicators_df[column] = pd.to_datetime(health_indicators_df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6062652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 419 entries, 0 to 418\n",
      "Columns: 149 entries, weight to Potential LOC Change (Non-Health)\n",
      "dtypes: bool(38), datetime64[ns](2), float64(56), int64(5), object(48)\n",
      "memory usage: 382.2+ KB\n"
     ]
    }
   ],
   "source": [
    "client_indicators = get_health_indicators(dataset_folder)\n",
    "health_indicators = client_indicators.merge(df_notables, left_on='client_id', right_on='clientId')\n",
    "health_indicators.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "744ab96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "health_indicators.to_csv(\"health_indicators_fall_detection.csv\", sep=',', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fca9ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
